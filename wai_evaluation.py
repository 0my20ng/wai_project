from wai_rag_system import WelfareNavigator
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows: ë§‘ì€ ê³ ë”•)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

def run_evaluation():
    # 1. RAG ì‹œìŠ¤í…œ ë¡œë“œ
    print("ğŸ§ª [Evaluation] í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    navigator = WelfareNavigator()
    
    # 2. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ (STEP 4-1)
    import json
    import random
    scenario_path = os.path.join('data', 'test_scenarios.json')
    try:
        with open(scenario_path, 'r', encoding='utf-8') as f:
            all_scenarios = json.load(f)
        
        # ì „ì²´ ì¤‘ 50ê°œë¥¼ ë¬´ì‘ìœ„ë¡œ ìƒ˜í”Œë§
        test_scenarios = random.sample(all_scenarios, min(50, len(all_scenarios)))
        print(f"ğŸ“‚ [Evaluation] ì „ì²´ {len(all_scenarios)}ê°œ ì¤‘ {len(test_scenarios)}ê°œì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ëœë¤í•˜ê²Œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"âš ï¸ {scenario_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ 5ê°œ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        test_scenarios = [
            {
                "id": 1,
                "persona": "ì›ì£¼ ê±°ì£¼ ëŒ€í•™ìƒ",
                "query": "ì›ì£¼ì‹œì— ì‚¬ëŠ” ëŒ€í•™ìƒì¸ë° ë“±ë¡ê¸ˆì´ë‘ ìƒí™œë¹„ ì§€ì›ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?",
                "expected_keywords": ["ì¥í•™", "í•™ìê¸ˆ", "ëŒ€í•™ìƒ"]
            },
            # ... (ê¸°íƒ€ ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤)
        ][:1] # ì˜ˆì‹œë¡œ í•˜ë‚˜ë§Œ ìœ ì§€í•˜ê±°ë‚˜ ì—ëŸ¬ ì²˜ë¦¬
    
    # 3. í‰ê°€ ì‹¤í–‰ ë° ì •ëŸ‰ì  ìˆ˜ì¹˜ ê³„ì‚° (STEP 4-2)
    print(f"\nğŸš€ ì´ {len(test_scenarios)}ê°œì˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n")
    
    correct_count = 0
    total_similarity_sum = 0
    total_results_count = 0
    
    results_summary = []

    for case in test_scenarios:
        print(f"--- [Scenario #{case['id']}] {case['persona']} ---")
        print(f"â“ ì§ˆë¬¸: {case['query']}")
        
        # ê²€ìƒ‰ ìˆ˜í–‰ (Top 3)
        search_results = navigator.search(case['query'], top_k=3)
        
        # ì •ë‹µ ì—¬ë¶€ íŒë‹¨ (Keyword Matching)
        is_correct = False
        matched_policy = "ì—†ìŒ"
        
        current_similarities = []
        
        print("ğŸ” ì¶”ì²œ ê²°ê³¼:")
        for res in search_results:
            current_similarities.append(res['similarity'])
            print(f"  - {res['ì‚¬ì—…ëª…']} (ìœ ì‚¬ë„: {res['similarity']:.4f})")
            
            # ì˜ˆìƒ í‚¤ì›Œë“œê°€ ì‚¬ì—…ëª…ì´ë‚˜ ë‚´ìš©ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            for keyword in case['expected_keywords']:
                if keyword in res['ì‚¬ì—…ëª…'] or keyword in res['ì§€ì›ëŒ€ìƒ'] or keyword in res['ì§€ì›ë‚´ìš©']:
                    is_correct = True
                    matched_policy = res['ì‚¬ì—…ëª…']
                    break
            if is_correct: break # í•˜ë‚˜ë¼ë„ ë§ìœ¼ë©´ ì •ë‹µ ì²˜ë¦¬
        
        if is_correct:
            correct_count += 1
            print(f"âœ… ê²°ê³¼: ì •ë‹µ (ë§¤ì¹­ëœ ì •ì±…: {matched_policy})")
        else:
            print(f"âŒ ê²°ê³¼: ì˜¤ë‹µ (ì ì ˆí•œ í‚¤ì›Œë“œ '{case['expected_keywords']}' ë¯¸ë°œê²¬)")
        
        print("")
        
        total_similarity_sum += sum(current_similarities)
        total_results_count += len(current_similarities)
        
        results_summary.append({
            "id": case['id'],
            "is_correct": is_correct,
            "avg_sim": np.mean(current_similarities)
        })

    # 4. ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
    accuracy = (correct_count / len(test_scenarios)) * 100
    avg_similarity_total = total_similarity_sum / total_results_count if total_results_count > 0 else 0
    
    print("\n" + "="*50)
    print("ğŸ“Š [STEP 4] ì„±ëŠ¥ í‰ê°€ ìµœì¢… ë¦¬í¬íŠ¸")
    print("="*50)
    print(f"1. Top-3 ì •í™•ë„ (Accuracy): {accuracy:.1f}%")
    print(f"   - (ëª©í‘œì¹˜ 90% ë‹¬ì„± ì—¬ë¶€: {'ì„±ê³µ ğŸ‰' if accuracy >= 90 else 'ë¯¸ë‹¬ (ë°ì´í„° ë³´ì™„ í•„ìš”) âš ï¸'})")
    print(f"2. í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ (Avg Similarity): {avg_similarity_total:.4f}")
    print("="*50)
    # ìƒì„¸ ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™” ì¤€ë¹„
    df_res = pd.DataFrame(results_summary)
    os.makedirs('data', exist_ok=True)
    save_path = os.path.join('data', "evaluation_result.csv")
    df_res.to_csv(save_path, index=False)
    
    # 5. ì‹œê°í™” (Visualization)
    print("\nğŸ“Š [Visualization] í‰ê°€ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
    
    # ê·¸ë˜í”„ 1: ì •í™•ë„ ë¹„êµ (Accuracy Chart)
    plt.figure(figsize=(8, 6))
    bars = plt.bar(['í˜„ì¬ ì •í™•ë„', 'ëª©í‘œ ì •í™•ë„'], [accuracy, 90], color=['#4CAF50', '#FFA000'])
    plt.ylim(0, 100)
    plt.title('AI ëª¨ë¸ Top-3 ì •í™•ë„ (Accuracy)', fontsize=16)
    plt.ylabel('ì •í™•ë„ (%)')
    
    # ìˆ˜ì¹˜ í‘œì‹œ
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 2, f'{yval}%', ha='center', va='bottom', fontsize=12)

    plt.savefig(os.path.join('data', 'evaluation_accuracy.png'))
    
    # ê·¸ë˜í”„ 2: ì‹œë‚˜ë¦¬ì˜¤ë³„ ìœ ì‚¬ë„ ì ìˆ˜ (Similarity per Scenario)
    plt.figure(figsize=(10, 6))
    colors = ['#2196F3' if x else '#F44336' for x in df_res['is_correct']]
    plt.bar(df_res['id'].astype(str), df_res['avg_sim'], color=colors)
    plt.axhline(y=avg_similarity_total, color='gray', linestyle='--', label='ì „ì²´ í‰ê·  ìœ ì‚¬ë„')
    plt.title('ì‹œë‚˜ë¦¬ì˜¤ë³„ í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ (Blue: ì •ë‹µ, Red: ì˜¤ë‹µ)', fontsize=16)
    plt.xlabel('ì‹œë‚˜ë¦¬ì˜¤ ID')
    plt.ylabel('ìœ ì‚¬ë„ ì ìˆ˜')
    plt.ylim(0, 1.0)
    plt.legend()
    
    plt.savefig(os.path.join('data', 'evaluation_similarity.png'))
    
    print(f"âœ… [ì‹œê°í™” ì™„ë£Œ] 'data/evaluation_accuracy.png', 'data/evaluation_similarity.png' ì €ì¥ ì™„ë£Œ")
    print(f"ğŸ’¾ ìƒì„¸ í‰ê°€ ê²°ê³¼ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_evaluation()
